{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-based planner\n",
    "\n",
    "This notebook demonstrates how to build a gradient-based planner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# These environment variables control where training and eval logs are written.\n",
    "# You can set these in your shell profile as well.\n",
    "os.environ[\"RUN_DIR\"] = \"runs\"\n",
    "os.environ[\"EVAL_RUN_DIR\"] = \"eval_runs\"\n",
    "os.environ[\"MODEL_DIR\"] = \"models\"\n",
    "os.environ[\"DATA_DIR\"] = \"data\"\n",
    "\n",
    "# This is used to set a constant Tensorboard port.\n",
    "os.environ[\"TENSORBOARD_PORT\"] = str(8989)\n",
    "\n",
    "import ml.api as ml  # Source: https://github.com/codekansas/ml-starter\n",
    "\n",
    "# Enables logging to `stdout`.\n",
    "ml.configure_logging(use_tqdm=True)\n",
    "\n",
    "# Imports these files to add them to the model and task registry.\n",
    "from usa.models.point2emb import Point2EmbModel\n",
    "from usa.tasks.clip_sdf import ClipSdfTask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "\n",
    "For this example, we use a clip recorded using the code in the `home-robot` repository [here](https://github.com/facebookresearch/home-robot). You can record your own clip on the Stretch robot and use that instead, by substituting the dataset path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "data_root = Path(\"data\")\n",
    "data_root.mkdir(exist_ok=True)\n",
    "dataset_path = data_root / \"dataset.pkl\"\n",
    "\n",
    "# We're downloading an existing dataset, but you can use your own instead.\n",
    "dataset_url = \"https://github.com/codekansas/usa/releases/download/v0.0.2/chris_lab.pkl\"\n",
    "if not dataset_path.exists():\n",
    "    with requests.get(dataset_url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(dataset_path, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "# Using the default config, but overriding the dataset.\n",
    "config = OmegaConf.load(\"config.yaml\")\n",
    "config.task.dataset = \"home_robot\"\n",
    "config.task.dataset_path = str(dataset_path)\n",
    "config.task.dataloader.train.batch_size = 2\n",
    "\n",
    "# We're using a small number of training steps to make the example easier\n",
    "# to follow, but this can be configured to improve the model quality.\n",
    "config.task.finished.max_steps = 500\n",
    "\n",
    "# We also only use the Tensorboard logger since it is easier to read.\n",
    "config.logger = [{\"name\": \"stdout\"}]\n",
    "\n",
    "# We still need to explicitly set these variables.\n",
    "config.trainer.exp_name = \"jupyter\"\n",
    "config.trainer.log_dir_name = \"test\"\n",
    "config.trainer.base_run_dir = \"runs\"\n",
    "config.trainer.run_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.task.dataloader.train.batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1;36mINFO\u001b[0m   \u001b[90m2023-06-02 16:30:33\u001b[0m [ml.trainers.base] Experiment directory: /scratch/pl2285/robot/usa/notebooks/runs/jupyter/run_1\n",
      "  \u001b[1;36mINFO\u001b[0m   \u001b[90m2023-06-02 16:30:33\u001b[0m [ml.core.registry] Components:\n",
      " ↪ \u001b[32mModel\u001b[0m: \u001b[36musa.models.point2emb.Point2EmbModel\u001b[0m (\u001b[34m/ext3/miniconda3/lib/python3.10/site-packages/usa/models/point2emb.py\u001b[0m)\n",
      " ↪ \u001b[32mTask\u001b[0m: \u001b[36musa.tasks.clip_sdf.ClipSdfTask\u001b[0m (\u001b[34m/ext3/miniconda3/lib/python3.10/site-packages/usa/tasks/clip_sdf.py\u001b[0m)\n",
      " ↪ \u001b[32mTrainer\u001b[0m: \u001b[36mml.trainers.sl.SupervisedLearningTrainer\u001b[0m (\u001b[34m/ext3/miniconda3/lib/python3.10/site-packages/ml/trainers/sl.py\u001b[0m)\n",
      " ↪ \u001b[32mOptimizer\u001b[0m: \u001b[36mml.optimizers.adam.AdamOptimizer\u001b[0m (\u001b[34m/ext3/miniconda3/lib/python3.10/site-packages/ml/optimizers/adam.py\u001b[0m)\n",
      " ↪ \u001b[32mLR Scheduler\u001b[0m: \u001b[36mml.lr_schedulers.linear.LinearLRScheduler\u001b[0m (\u001b[34m/ext3/miniconda3/lib/python3.10/site-packages/ml/lr_schedulers/linear.py\u001b[0m)\n",
      " ↪ \u001b[32mLauncher\u001b[0m: \u001b[36mml.launchers.slurm.SlurmLauncher\u001b[0m (\u001b[34m/ext3/miniconda3/lib/python3.10/site-packages/ml/launchers/slurm.py\u001b[0m)\n",
      "\u001b[1;33mWARNING\u001b[0m  \u001b[90m2023-06-02 16:30:33\u001b[0m [ml.trainers.base] Overwriting config /scratch/pl2285/robot/usa/notebooks/runs/jupyter/run_1/config.yaml:\n",
      " ↪ \u001b[32m+\u001b[0m launcher.master_port=29498\n",
      " ↪ \u001b[31m-\u001b[0m launcher.master_port=24405\n",
      "\u001b[1;33mWARNING\u001b[0m  \u001b[90m2023-06-02 16:30:34\u001b[0m [ml.utils.timer] Finished getting datasets in 0.581 seconds\n",
      "  \u001b[1;36mINFO\u001b[0m   \u001b[90m2023-06-02 16:30:35\u001b[0m [stdout] \u001b[1;33mvalid\u001b[0m [\u001b[95m1 second\u001b[0m] {\"\u001b[96mloss\u001b[0m\": {\"clip\": 2.431, \"sdf\": 0.3259}, \"\u001b[96mtask\u001b[0m\": {\"pmax\": 1.168, \"pmin\": -0.501}, \"\u001b[96mtimers\u001b[0m\": {\"epoch\": 55, \"\u001b[36mdt\u001b[0m\": {\"forward\": 0.09115, \"get_single_loss\": 0.000174, \"iter\": 4.071, \"log_losses\": 0.0002959}, \"\u001b[36mhours\u001b[0m\": {\"epoch\": -1.373e-10}, \"\u001b[36msamples\u001b[0m\": {\"hour\": 0, \"second\": 0, \"total\": 1000}, \"\u001b[36msteps\u001b[0m\": {\"hour\": 0, \"second\": 0, \"total\": 500}}}\n",
      "  \u001b[1;36mINFO\u001b[0m   \u001b[90m2023-06-02 16:30:35\u001b[0m [ml.trainers.base] Saving checkpoint to /scratch/pl2285/robot/usa/notebooks/runs/jupyter/run_1/checkpoints/ckpt.500.pt\n",
      "  \u001b[1;36mINFO\u001b[0m   \u001b[90m2023-06-02 16:30:35\u001b[0m [ml.trainers.sl] Finished training after 55 epochs, 500 steps, 1000 samples\n",
      "  \u001b[1;36mINFO\u001b[0m   \u001b[90m2023-06-02 16:30:35\u001b[0m [ml.trainers.base] Exiting training job for /scratch/pl2285/robot/usa/notebooks/runs/jupyter/run_1/config.yaml\n"
     ]
    }
   ],
   "source": [
    "objs = ml.instantiate_config(config)\n",
    "\n",
    "# Unpacking the different components.\n",
    "model = objs.model\n",
    "task = objs.task\n",
    "optimizer = objs.optimizer\n",
    "lr_scheduler = objs.lr_scheduler\n",
    "trainer = objs.trainer\n",
    "\n",
    "#from tensorboard import notebook\n",
    "\n",
    "# Show Tensorboard inside the notebook.\n",
    "#notebook.display(port=int(os.environ['TENSORBOARD_PORT']))\n",
    "\n",
    "# Runs the training loop.\n",
    "trainer.train(model, task, optimizer, lr_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a planner\n",
    "\n",
    "This example demonstrates how to use the trained model to build a planner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bounds: 100%|██████████| 18/18 [00:00<00:00, 459.21it/s]\n",
      "Occupancy Map: 100%|██████████| 18/18 [00:00<00:00, 464.29it/s]\n",
      "Bounds: 100%|██████████| 18/18 [00:00<00:00, 494.51it/s]\n",
      "Occupancy Map: 100%|██████████| 18/18 [00:00<00:00, 456.21it/s]\n",
      "100%|██████████| 143/143 [00:00<00:00, 314.35it/s]\n",
      "Bounds: 100%|██████████| 18/18 [00:00<00:00, 470.66it/s]\n",
      "Occupancy Map: 100%|██████████| 18/18 [00:00<00:00, 448.21it/s]\n",
      "100%|██████████| 143/143 [00:00<00:00, 356.26it/s]\n"
     ]
    }
   ],
   "source": [
    "#from usa.planners.clip_sdf import GradientPlanner\n",
    "import sys\n",
    "sys.path.append('../usa')\n",
    "from planners.clip_sdf import GradientPlanner, AStarPlanner\n",
    "\n",
    "# Builds the planner from the model and task. The planner\n",
    "# hyperparameters can be configured as needed.\n",
    "gradient_planner = GradientPlanner(\n",
    "    dataset=task._dataset(),\n",
    "    model=model,\n",
    "    task=task,\n",
    "    device=task._device,\n",
    "    num_optimization_steps = 10,\n",
    "    lr = 1e-2\n",
    ")\n",
    "\n",
    "grid_planner = AStarPlanner(\n",
    "    dataset=task._dataset(),\n",
    "    model=model,\n",
    "    task=task,\n",
    "    device=task._device,\n",
    "    \n",
    "    # The heuristic to use for AStar\n",
    "    heuristic=\"euclidean\",\n",
    "    # The grid resolution\n",
    "    resolution=0.1,\n",
    "    # Where to store cache artifacts\n",
    "    cache_dir=None,\n",
    ").double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = gradient_planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0.07773437500000036, 0.060156250000000355), (0.177734375, 0.16015625), (0.2777343750000001, 0.2601562500000001), (0.3777343750000002, 0.3601562500000002), (0.47773437500000027, 0.46015625000000027), (0.5777343750000004, 0.5601562500000004), (0.677734375, 0.66015625), (0.7777343750000001, 0.7601562500000005), (0.8777343750000002, 0.8601562500000002), (1, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 233.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0778, 0.0602],\n",
      "        [0.1777, 0.1602],\n",
      "        [0.2778, 0.2603],\n",
      "        [0.3777, 0.3601],\n",
      "        [0.4778, 0.4602],\n",
      "        [0.5776, 0.5601],\n",
      "        [0.6777, 0.6602],\n",
      "        [0.7778, 0.7603],\n",
      "        [0.8779, 0.8604],\n",
      "        [1.0000, 1.0000]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0782, 0.0622],\n",
      "        [0.1771, 0.1595],\n",
      "        [0.2778, 0.2603],\n",
      "        [0.3777, 0.3601],\n",
      "        [0.4778, 0.4602],\n",
      "        [0.5776, 0.5601],\n",
      "        [0.6777, 0.6602],\n",
      "        [0.7773, 0.7598],\n",
      "        [0.8784, 0.8623],\n",
      "        [1.0000, 1.0000]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0790, 0.0659],\n",
      "        [0.1761, 0.1587],\n",
      "        [0.2778, 0.2603],\n",
      "        [0.3777, 0.3601],\n",
      "        [0.4778, 0.4602],\n",
      "        [0.5776, 0.5601],\n",
      "        [0.6777, 0.6602],\n",
      "        [0.7764, 0.7588],\n",
      "        [0.8799, 0.8652],\n",
      "        [1.0000, 1.0000]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0801, 0.0704],\n",
      "        [0.1749, 0.1578],\n",
      "        [0.2776, 0.2600],\n",
      "        [0.3777, 0.3601],\n",
      "        [0.4778, 0.4602],\n",
      "        [0.5776, 0.5601],\n",
      "        [0.6772, 0.6597],\n",
      "        [0.7749, 0.7578],\n",
      "        [0.8813, 0.8691],\n",
      "        [1.0000, 1.0000]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0813, 0.0750],\n",
      "        [0.1737, 0.1576],\n",
      "        [0.2771, 0.2595],\n",
      "        [0.3779, 0.3604],\n",
      "        [0.4778, 0.4602],\n",
      "        [0.5776, 0.5601],\n",
      "        [0.6768, 0.6592],\n",
      "        [0.7739, 0.7573],\n",
      "        [0.8828, 0.8730],\n",
      "        [1.0000, 1.0000]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0826, 0.0791],\n",
      "        [0.1727, 0.1582],\n",
      "        [0.2761, 0.2588],\n",
      "        [0.3782, 0.3606],\n",
      "        [0.4778, 0.4602],\n",
      "        [0.5776, 0.5601],\n",
      "        [0.6758, 0.6582],\n",
      "        [0.7729, 0.7573],\n",
      "        [0.8843, 0.8770],\n",
      "        [1.0000, 1.0000]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0839, 0.0823],\n",
      "        [0.1721, 0.1597],\n",
      "        [0.2749, 0.2578],\n",
      "        [0.3782, 0.3606],\n",
      "        [0.4778, 0.4602],\n",
      "        [0.5776, 0.5601],\n",
      "        [0.6748, 0.6572],\n",
      "        [0.7725, 0.7583],\n",
      "        [0.8853, 0.8804],\n",
      "        [1.0000, 1.0000]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0850, 0.0845],\n",
      "        [0.1720, 0.1619],\n",
      "        [0.2734, 0.2568],\n",
      "        [0.3779, 0.3604],\n",
      "        [0.4780, 0.4604],\n",
      "        [0.5776, 0.5601],\n",
      "        [0.6733, 0.6562],\n",
      "        [0.7729, 0.7598],\n",
      "        [0.8862, 0.8828],\n",
      "        [1.0000, 1.0000]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0860, 0.0856],\n",
      "        [0.1724, 0.1647],\n",
      "        [0.2720, 0.2563],\n",
      "        [0.3774, 0.3601],\n",
      "        [0.4783, 0.4607],\n",
      "        [0.5771, 0.5596],\n",
      "        [0.6719, 0.6553],\n",
      "        [0.7734, 0.7622],\n",
      "        [0.8867, 0.8843],\n",
      "        [1.0000, 1.0000]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0868, 0.0860],\n",
      "        [0.1731, 0.1676],\n",
      "        [0.2705, 0.2563],\n",
      "        [0.3767, 0.3596],\n",
      "        [0.4785, 0.4609],\n",
      "        [0.5767, 0.5591],\n",
      "        [0.6704, 0.6548],\n",
      "        [0.7744, 0.7646],\n",
      "        [0.8872, 0.8853],\n",
      "        [1.0000, 1.0000]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate waypoints between two explicit points.\n",
    "waypoints = planner.plan(start_xy=(0, 0), end_xy=(1, 1))\n",
    "\n",
    "# Generates waypoints from a start location to a semantic target.\n",
    "#waypoints = planner.plan(start_xy=(0, 0), end_goal=\"The chair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis(waypoints):\n",
    "    total = 0\n",
    "    for i in range(len(waypoints) - 1):\n",
    "        total += torch.linalg.norm(torch.tensor(\n",
    "            [waypoints[i + 1][0] - waypoints[i][0], waypoints[i + 1][1] - waypoints[i][1]]).float())\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4146)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis(waypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0.07773437500000036, 0.060156250000000355), (0.07773437500000036, 0.16015625), (0.177734375, 0.2601562500000001), (0.2777343750000001, 0.3601562500000002), (0.3777343750000002, 0.46015625000000027)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 269.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0778, 0.0602],\n",
      "        [0.0778, 0.1602],\n",
      "        [0.1777, 0.2603],\n",
      "        [0.2778, 0.3601],\n",
      "        [0.3777, 0.4602]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[0.0000, 0.0000],\n",
      "        [0.0699, 0.0632],\n",
      "        [0.0854, 0.1586],\n",
      "        [0.1771, 0.2598],\n",
      "        [0.2778, 0.3601],\n",
      "        [0.4202, 1.3623]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [ 0.0569,  0.0685],\n",
      "        [ 0.0980,  0.1560],\n",
      "        [ 0.1643,  0.2462],\n",
      "        [ 0.2869,  0.3923],\n",
      "        [-1.6934,  0.8506]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [ 0.0431,  0.0745],\n",
      "        [ 0.1103,  0.1517],\n",
      "        [ 0.1313,  0.2076],\n",
      "        [ 0.2656,  0.4514],\n",
      "        [-3.7051,  0.2231]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [ 0.0332,  0.0800],\n",
      "        [ 0.1157,  0.1439],\n",
      "        [ 0.0713,  0.1162],\n",
      "        [ 0.1913,  0.5518],\n",
      "        [-5.8008,  0.5142]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[ 0.0000e+00,  0.0000e+00],\n",
      "        [ 2.9556e-02,  8.3069e-02],\n",
      "        [ 1.1078e-01,  1.2939e-01],\n",
      "        [-6.6032e-03, -5.5054e-02],\n",
      "        [ 2.8320e-02,  7.3096e-01],\n",
      "        [-7.7852e+00, -1.9336e+00]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [ 0.0296,  0.0803],\n",
      "        [ 0.0991,  0.1116],\n",
      "        [-0.0818, -0.3359],\n",
      "        [-0.2634,  0.9683],\n",
      "        [-8.7031, -4.9062]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [ 0.0276,  0.0688],\n",
      "        [ 0.0865,  0.0936],\n",
      "        [-0.1279, -0.7383],\n",
      "        [-0.5425,  1.1289],\n",
      "        [-9.4141, -9.3594]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[  0.0000,   0.0000],\n",
      "        [  0.0164,   0.0468],\n",
      "        [  0.0797,   0.0751],\n",
      "        [ -0.0243,  -1.0654],\n",
      "        [ -0.9546,   1.2412],\n",
      "        [-10.7031, -12.8594]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n",
      "tensor([[ 0.0000e+00,  0.0000e+00],\n",
      "        [-6.9504e-03,  1.3237e-02],\n",
      "        [ 8.3191e-02,  5.8350e-02],\n",
      "        [ 1.2619e-02, -1.6650e+00],\n",
      "        [-1.1211e+00,  1.4551e+00],\n",
      "        [-1.1164e+01, -1.5680e+01]], device='cuda:0', dtype=torch.float16,\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0),\n",
       " (-0.042724609375, -0.0335693359375),\n",
       " (0.1044921875, 0.0419921875),\n",
       " (0.242431640625, -2.486328125),\n",
       " (-1.4365234375, 1.591796875),\n",
       " (-9.1875, -18.875)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planner.plan(start_xy=(0, 0), end_goal=\"The chair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING\u001b[0m  \u001b[90m2023-06-02 16:06:06\u001b[0m [matplotlib.ticker] Locator attempting to generate 8702 ticks ([1.2598, ..., 3.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "images = plt.figure(figsize = (50, 35))\n",
    "depths = plt.figure(figsize = (50, 35))\n",
    "for i, items in enumerate(task._dataset()):\n",
    "    ax1 = images.add_subplot(4, 5, i + 1)\n",
    "    ax1.imshow(items[0].permute(1, 2, 0))\n",
    "    ax1.axis('off')\n",
    "    ax2 = depths.add_subplot(4, 5, i + 1)\n",
    "    #print(items[1])\n",
    "    depth = items[1].clamp(1, 3)\n",
    "    #ax2.imshow(items[1].permute(1, 2, 0), vmax = items[1].max(), vmin = items[1].min())\n",
    "    #xi, yi = torch.meshgrid(torch.linspace(0, 1, depth.shape[1]), torch.linspace(0, 1, depth.shape[2]) )\n",
    "    #ax2.contourf(xi, yi, depth[0], levels = 10000)\n",
    "    ax2.imshow(depth[0])\n",
    "    ax2.axis('off')\n",
    "plt.colorbar()\n",
    "images, depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "cs2590"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
